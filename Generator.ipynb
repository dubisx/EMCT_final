{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7ARWKKgdQLnoKhm3DvCOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dubisx/EMCT_final/blob/main/Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n42cJmouxDxS",
        "outputId": "9f4aeaeb-d30f-405f-dfba-e3596bc6b1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting miditok\n",
            "  Downloading miditok-2.0.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting miditoolkit>=0.1.16\n",
            "  Downloading miditoolkit-0.1.16-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy<1.24,>=1.19 in /usr/local/lib/python3.9/dist-packages (from miditok) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from miditok) (4.65.0)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mido, miditoolkit, miditok\n",
            "Successfully installed miditok-2.0.3 miditoolkit-0.1.16 mido-1.2.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install miditok\n",
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy\n",
        "import miditok\n",
        "import tqdm\n",
        "from miditok import MIDILike, MIDITokenizer, REMI\n",
        "import pathlib\n",
        "from miditok.constants import CHORD_MAPS\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Config, Trainer, TrainingArguments, GenerationConfig, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2JWQ_xsxafl",
        "outputId": "ad3bc99e-72c0-4494-858a-39c5d2e1641e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/gdrive/MyDrive/model_f/model2/\"\n",
        "\n",
        "pitch_range = range(21, 109)\n",
        "beat_res = {(0, 4): 8, (4, 12): 4}\n",
        "nb_velocities = 32\n",
        "additional_tokens = {'Chord': True, 'Rest': True, 'Tempo': True,\n",
        "                     'rest_range': (2, 8),  # (half, 8 beats)\n",
        "                     'nb_tempos': 32,  # nb of tempo bins\n",
        "                     'tempo_range': (40, 250),  # (min, max)\n",
        "                     'Program': False,\n",
        "                     \"chord_maps\": CHORD_MAPS,\n",
        "                     \"chord_tokens_with_root_note\": True,\n",
        "                     \"chord_unknown\": False}\n",
        "special_tokens = [\"PAD\", \"BOS\", \"EOS\"]\n",
        "\n",
        "tokenizer = MIDILike(pitch_range, beat_res, nb_velocities, additional_tokens, special_tokens=special_tokens)\n",
        "\n",
        "print('Loading the model...')\n",
        "\n",
        "config = GPT2Config(\n",
        "    vocab_size=1000,\n",
        "    n_positions=2048,\n",
        "    n_embd=512,\n",
        "    n_layer=8,\n",
        "    n_head=8,\n",
        "    n_inner=2048,\n",
        "    resid_pdrop=.1,\n",
        "    embd_pdrop=.1,\n",
        "    attn_pdrop=.1,\n",
        "    padding_token_id=tokenizer['PAD_None'],\n",
        "    bos_token_id=tokenizer['BOS_None'],\n",
        "    eos_token_id=tokenizer['EOS_None'],\n",
        ")\n",
        "model = TFGPT2LMHeadModel(config)\n",
        "\n",
        "#model.save_pretrained('/content/gdrive/MyDrive/models/')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABXEpdOMxdkN",
        "outputId": "b5d908c5-e6f9-4306-f970-10e5f988c50c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "IiSFuHtzxS1T",
        "outputId": "fea910ec-749f-4676-ffeb-c4c2badb7768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/gdrive/MyDrive/model_f/model2/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel at 0x7fb1fe0595e0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# defining our optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "# definining our loss function\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# defining our metric which we want to observe\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "# compiling the model\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])"
      ],
      "metadata": {
        "id": "mYt0t9gOyIAp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from miditok.utils import get_midi_programs\n",
        "from miditoolkit import MidiFile\n",
        "\n",
        "\n",
        "midi_path = '/content/gdrive/MyDrive/example midi/midi_example.mid'\n",
        "\n",
        "tokenizer.learn_bpe(\n",
        "    vocab_size=1000,\n",
        "    tokens_paths=list(Path(\"/content/gdrive/MyDrive/tokens_noBPE\").glob('**/*.json')),\n",
        "    out_dir=Path('/content/gdrive/MyDrive/tokens_BPE')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsgWikABOFk",
        "outputId": "749a394c-e524-4737-cce4-7a7ddcf0d0eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading token files: 100%|██████████| 5456/5456 [01:48<00:00, 50.42it/s]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "midi_path = '/content/gdrive/MyDrive/example midi/midi/midi_example.mid'\n",
        "\n",
        "midi = MidiFile(midi_path)\n",
        "token = tokenizer(midi)  # automatically detects MidiFile, paths or tokens before converting them\n"
      ],
      "metadata": {
        "id": "85P_-SIVlxGt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token[0].ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDjivfILD3wb",
        "outputId": "d5a323f0-0fb8-440a-ed18-d671065eb251"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[328, 904, 48, 204, 52, 438, 21, 201, 226, 109, 24, 461, 112, 17, 204, 213, 702, 133, 136, 271, 38, 204, 41, 201, 45, 438, 64, 205, 217, 958, 64, 201, 65, 347, 152, 213, 64, 204, 213, 882, 105, 16, 201, 217, 587, 211, 126, 104, 679, 794, 45, 204, 48, 202, 222, 152, 214, 67, 534, 65, 338, 155, 64, 862, 133, 136, 882, 102, 129, 520, 40, 200, 43, 202, 389, 226, 128, 40, 204, 62, 202, 217, 958, 740, 201, 217, 131, 135, 958, 104, 128, 904, 48, 204, 52, 438, 21, 201, 226, 109, 24, 461, 112, 17, 204, 213, 136, 702, 133, 271, 38, 204, 41, 201, 904, 234, 105, 16, 201, 217, 126, 587, 211, 104, 679, 794, 45, 204, 48, 202, 241, 587, 820, 102, 520, 40, 200, 43, 202, 389, 226, 128, 40, 204, 225, 131, 135, 780, 104]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# savetok = Path('/content/gdrive/MyDrive/example midi/token1.json')\n",
        "\n",
        "# tokenizer.save_tokens(token, savetok)"
      ],
      "metadata": {
        "id": "HcJAown6mytC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "directory = '/content/gdrive/MyDrive/example midi/tokens/'\n",
        "\n",
        "\n",
        "for fname in os.listdir(directory):                     # for each file in the directory\n",
        "    with open(os.path.join(directory, fname)) as i:     # open the file\n",
        "        data = json.load(i)   "
      ],
      "metadata": {
        "id": "GEEpNQuMn1mr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [data['ids'][0][:300]]\n"
      ],
      "metadata": {
        "id": "q6QqZy8cBBta"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " I have managed to convert a new MIDI to a BPE encoded token, however I am unsure on how to feed the data into the model.generate function to generate a new sequence."
      ],
      "metadata": {
        "id": "nL07Onqdrj71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=512,  # extends samples by 512 tokens\n",
        "    num_beams=1,        # no beam search\n",
        "    do_sample=True,     # but sample instead\n",
        "    temperature=0.9,\n",
        "    top_k=15,\n",
        "    top_p=0.95,\n",
        "    epsilon_cutoff=3e-4,\n",
        "    eta_cutoff=1e-3,\n",
        "    pad_token_id=config.padding_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "9Tu0912A0Mqu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(prompt, max_length=1000, do_sample=True, top_p=0.95, top_k=60)\n"
      ],
      "metadata": {
        "id": "6pPuCSZ7o68Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633d4889-7166-4d6d-86a5-64e9369fdfd9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDNOd1rkJPYH",
        "outputId": "31a26aaf-89af-4bbf-f9af-cb8b09880daf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[328 904  48 204  52 438  21 201 226 109  24 461 112  17 204 213 702 133\n",
            "  136 271  38 204  41 201  45 438  64 205 217 958  64 201  65 347 152 213\n",
            "   64 204 213 882 105  16 201 217 587 211 126 104 679 794  45 204  48 202\n",
            "  222 152 214  67 534  65 338 155  64 862 133 136 882 102 129 520  40 200\n",
            "   43 202 389 226 128  40 204  62 202 217 958 740 201 217 131 135 958 104\n",
            "  128 904  48 204  52 438  21 201 226 109  24 461 112  17 204 213 136 702\n",
            "  133 271  38 204  41 201 904 234 105  16 201 217 126 587 211 104 679 794\n",
            "   45 204  48 202 241 587 820 102 520  40 200  43 202 389 226 128  40 204\n",
            "  225 131 135 780 104 708 940 238 238 122 661  80  80 355 602 305 566  81\n",
            "  870 878 747 224  44 566 800 951 305 536 744 514 708 599 837 389  65 238\n",
            "  619 191 876 773 191 191 153 105 472 536 195 372 949 776  82 968 239 949\n",
            "  886 744 601 489 239 744 663 864 372 536 502 647 239 705  47 744 122 601\n",
            "  467 122 968  90 906 122 304 655 863 949 870 289 215 837 756 983 191 189\n",
            "  154  94 211 367 467 215 299  46 881 536 314 239 776  94 211 949 534 122\n",
            "  717 154 362 249 461 258 372 485 485 498 372  39 593  46 258 704 464 906\n",
            "  876 218 258  94 298 104 372 860 593 931 142 470 430 769 534 148 371 644\n",
            "  807 406 104 265 464 489 949 651 949 455 298  34 245 546 800 276 746 663\n",
            "  536 372 118 754 644  77 239 897 878  84  48 402 360 535 363 298 464 911\n",
            "   65 603 949 390 826 947 876 501 881 203 886 744 351 861 794 776 536 192\n",
            "  341 298 715 390 239 912 245 502 800 636 239 746 367 864 498 636 906 304\n",
            "  104 377 567 748 708  89 245 708 949 655 705 245 245  94 506  20 211 501\n",
            "   99 644 363 341 949 515 949 209 881 399 501 471 299 118 754 644 644 940\n",
            "   84 370 860  86 661 471  39 540 540 304 238 472 485  87 794 968 651 717\n",
            "  191 203 390  44 105  84 495 949 859 663 645 540 704 872 968 489 305 998\n",
            "  655 649 299 773 644 924 239 599 578  65 704 870 679 198 104 824  86 498\n",
            "  239  94  94 211 176 239 800 969 541 540  65  54 218 103 239 717 636 154\n",
            "  704 238 985 485 304 546 705 581 692 931 776 383 534 448  65 708 536  44\n",
            "  360 355 876 239 705 705  39 479 590 390 540 536 794 546  63 644 316 189\n",
            "  964 546 776  94 489  65 968 964 897 239 496 261 479 479 441 679 245 801\n",
            "  663 628 520 238 402  87 231 495 659 776 535 225 231 118 717 968 721 351\n",
            "  876 633 661 661  77 104 794 596 269 105  65 821 287 364 105 567 501 659\n",
            "  715 708 231  94 501 754 850 486 945 786 864 679 715 304 840 452 311 122\n",
            "  968 298  80  99 536 958 540 239 230 964  34 479 876 145 462 430 189 906\n",
            "  301 593 906 489  80 949 644  85 622 821 636 636 863 501 546 911  87 717\n",
            "  821 821  65 230 531 304 394 312 390 489 472 392 912 680 806 231 299 870\n",
            "  451  46 513 534 501 104 601 661 663  87 636 636 949 614 470 679 794 601\n",
            "  672 312 748 552 485 171  87 821 861 400 782  71 886 457  78 840  44 305\n",
            "  968 534  65 189 878 341 708 599 846 846 721 171 134 599 599 181  65 134\n",
            "  464 239 239 238 629 864 949 717 127 303  80 389 679 940  80 578 931 984\n",
            "  103  65 748 312  99 255 195 800 586 557 390 190 744 616 836 464 142 906\n",
            "  383 348 464 704 969  34 727 540 304 455 614 661 239  24 708 145 906 601\n",
            "  154 364 881 599 316 776 546 153 498 154 312 379 597 881 245 394 360 679\n",
            "  949 154 153 431 485 814  17 605 104 821 367 669 557 624  78 153 363 360\n",
            "  906  65 569 642 578 982 897 392 644 360 495 499 593 748 455 776 807 748\n",
            "  540 628 860 889 864 451 688 969 176 360 118 239 864 495 747 891  44 540\n",
            "  794  78 664 417 176 694 931 800 189 776 881  65 540 344 940 891 472 800\n",
            "   24  38  80 215 801  30 360 586 390 731  94 897 489 596 661 540 789 886\n",
            "   89 601 301 464 120 118 889 148 891 949 389 912 839 470 299 464 390 360\n",
            "  355  45  56 660 231 544 731 122  60 238 644 651 864 534 472 406 663 494\n",
            "  737 276 229 171 238 388 118 154 485 864 964 305  71 301 430 364 599 601\n",
            "  864 392 390 801 360 341 176 176 906 889  87 717 859  80 704 968 964 806\n",
            "  601 534 748  87 807 103 578 372 301 878 341 776 891 601 601 239 105 363\n",
            "  299 964 601 599 238 118 655 485 911 599 863 924 891 949 889 235 312 105\n",
            "   65  86 419 122  39 737 731 695  45 495 148 704 801 840 536  94 231 470\n",
            "  686 154  44 344 681 947  46  58   5 289 541 245 601 479 245 341 176 254\n",
            "  968 479 461 601 154 154 535 110 312 501]], shape=(1, 1000), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-aBY-taQKqkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}