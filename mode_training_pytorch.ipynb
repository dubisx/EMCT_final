{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Callable, Any, Union\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from miditok import MIDILike, MIDITokenizer\n",
    "from miditoolkit import MidiFile\n",
    "from tqdm import tqdm\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_path = Path(\"C:/Users/simas/OneDrive/Desktop/alawais midi/tokens_BPE\")\n",
    "tokens_paths = list(tokens_path.glob(\"**/*.json\"))\n",
    "tokenizer = MIDILike()\n",
    "vocab_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDataset(tf.keras.utils.Sequence):\n",
    "    r\"\"\"Dataset for generator training\n",
    "\n",
    "    :param files_paths: list of paths to files to load.\n",
    "    :param tokenizer: tokenizer object, to use to load MIDIs instead of tokens. (default: None)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, files_paths: List[Path], min_seq_len: int, max_seq_len: int, tokenizer: MIDITokenizer = None):\n",
    "        samples = []\n",
    "\n",
    "        for file_path in tqdm(files_paths, desc=f'Loading data: {files_paths[0].parent}'):\n",
    "            if file_path.suffix in [\"mid\", \"midi\", \"MID\", \"MIDI\"]:\n",
    "                midi = MidiFile(file_path)\n",
    "                for _ in range(len(midi.instruments) - 1):\n",
    "                    del midi.instruments[1]  # removes all tracks except first one\n",
    "                tokens = tokenizer.midi_to_tokens(midi)[0].ids\n",
    "            else:\n",
    "                with open(file_path) as json_file:\n",
    "                    tokens = json.load(json_file)['ids'][0]  # first track\n",
    "            i = 0\n",
    "            while i < len(tokens):\n",
    "                if i >= len(tokens) - min_seq_len:\n",
    "                    break  # last sample is too short\n",
    "                samples.append(np.array(tokens[i:i + max_seq_len]))\n",
    "                i += len(samples[-1])  # could be replaced with max_seq_len\n",
    "\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, np.ndarray]:\n",
    "        return {\"input_ids\": self.samples[idx], \"labels\": self.samples[idx]}\n",
    "    \n",
    "    def __len__(self) -> int: return len(self.samples)\n",
    "\n",
    "    def __repr__(self): return self.__str__()\n",
    "\n",
    "    def __str__(self) -> str: return 'No data loaded' if len(self) == 0 else f'{len(self.samples)} samples'\n",
    "\n",
    "\n",
    "def _pad_batch(examples: List[Dict[str, np.ndarray]], pad_token: int) -> np.ndarray:\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "\n",
    "    length_of_first = examples[0][\"input_ids\"].shape[0]\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "    are_tensors_same_length = all(x[\"input_ids\"].shape[0] == length_of_first for x in examples)\n",
    "    if are_tensors_same_length:\n",
    "        return np.stack([e[\"input_ids\"] for e in examples], axis=0)\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences([e[\"input_ids\"] for e in examples], padding='post', value=pad_token)\n",
    "\n",
    "class DataCollatorGen:\n",
    "    def __init__(self, pad_token: int):\n",
    "        \"\"\"Collator that simply pad the input sequences.\n",
    "        Input_ids will be padded with the pad token given, while labels will be\n",
    "        padded with -100.\n",
    "\n",
    "        :param pad_token: pas token\n",
    "        \"\"\"\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, np.ndarray]:\n",
    "        x, y = _pad_batch(batch, self.pad_token), _pad_batch(batch, -100)\n",
    "        return {\"input_ids\": x, \"labels\": y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: C:\\Users\\simas\\OneDrive\\Desktop\\alawais midi\\tokens_BPE: 100%|██████████| 198390/198390 [02:56<00:00, 1121.87it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MIDIDataset(\n",
    "    tokens_paths, max_seq_len=512, min_seq_len=256, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset, output_types={\"input_ids\": tf.int32, \"labels\": tf.int32}\n",
    ").take(train_size), tf.data.Dataset.from_generator(\n",
    "    lambda: dataset, output_types={\"input_ids\": tf.int32, \"labels\": tf.int32}\n",
    ").skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 64844, validation dataset size: 16211\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {train_size}, validation dataset size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338,)\n",
      "(363,)\n",
      "(369,)\n",
      "(362,)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "#print shape of first 5 samples\n",
    "for x in train_dataset.take(5):\n",
    "    print(x[\"input_ids\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
