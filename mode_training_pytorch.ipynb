{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Callable, Any, Union\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from miditok import REMI, MIDITokenizer\n",
    "from miditoolkit import MidiFile\n",
    "from tqdm import tqdm\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "from torch import Tensor, LongTensor, stack\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtoolkit.train import select_device\n",
    "from torchtoolkit.data import create_subsets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_path = Path(\"C:/Users/simas/OneDrive/Desktop/alawais midi/tokens_BPE\")\n",
    "tokens_paths = list(tokens_path.glob(\"**/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: C:\\Users\\simas\\OneDrive\\Desktop\\alawais midi\\tokens_BPE:   2%|‚ñè         | 3794/198390 [00:25<32:54, 98.54it/s]  "
     ]
    }
   ],
   "source": [
    "\n",
    "class MIDIDataset(Dataset):\n",
    "    r\"\"\"Dataset for generator training\n",
    "\n",
    "    :param files_paths: list of paths to files to load.\n",
    "    :param tokenizer: tokenizer object, to use to load MIDIs instead of tokens. (default: None)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, files_paths: List[Path], min_seq_len: int, max_seq_len: int, tokenizer: MIDITokenizer = None):\n",
    "        samples = []\n",
    "\n",
    "        for file_path in tqdm(files_paths, desc=f'Loading data: {files_paths[0].parent}'):\n",
    "            if file_path.suffix in [\"mid\", \"midi\", \"MID\", \"MIDI\"]:\n",
    "                midi = MidiFile(file_path)\n",
    "                for _ in range(len(midi.instruments) - 1):\n",
    "                    del midi.instruments[1]  # removes all tracks except first one\n",
    "                tokens = tokenizer.midi_to_tokens(midi)[0].ids\n",
    "            else:\n",
    "                with open(file_path) as json_file:\n",
    "                    tokens = json.load(json_file)['ids'][0]  # first track\n",
    "            i = 0\n",
    "            while i < len(tokens):\n",
    "                if i >= len(tokens) - min_seq_len:\n",
    "                    break  # last sample is too short\n",
    "                samples.append(LongTensor(tokens[i:i + max_seq_len]))\n",
    "                i += len(samples[-1])  # could be replaced with max_seq_len\n",
    "\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, LongTensor]:\n",
    "        return {\"input_ids\": self.samples[idx], \"labels\": self.samples[idx]}\n",
    "    \n",
    "    def __len__(self) -> int: return len(self.samples)\n",
    "\n",
    "    def __repr__(self): return self.__str__()\n",
    "\n",
    "    def __str__(self) -> str: return 'No data loaded' if len(self) == 0 else f'{len(self.samples)} samples'\n",
    "\n",
    "\n",
    "def _pad_batch(examples: List[Dict[str, LongTensor]], pad_token: int) -> LongTensor:\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "\n",
    "    length_of_first = examples[0][\"input_ids\"].size(0)\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "    are_tensors_same_length = all(x[\"input_ids\"].size(0) == length_of_first for x in examples)\n",
    "    if are_tensors_same_length:\n",
    "        return stack([e[\"input_ids\"] for e in examples], dim=0).long()\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    return pad_sequence([e[\"input_ids\"] for e in examples], batch_first=True, padding_value=pad_token).long()\n",
    "\n",
    "\n",
    "class DataCollatorGen(DataCollatorMixin):\n",
    "    def __init__(self, pad_token: int, return_tensors: str = \"pt\"):\n",
    "        \"\"\"Collator that simply pad the input sequences.\n",
    "        Input_ids will be padded with the pad token given, while labels will be\n",
    "        padded with -100.\n",
    "\n",
    "        :param pad_token: pas token\n",
    "        :param return_tensors:\n",
    "        \"\"\"\n",
    "        self.pad_token = pad_token\n",
    "        self.return_tensors = return_tensors\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Any]], return_tensors=None) -> Dict[str, LongTensor]:\n",
    "        x, y = _pad_batch(batch, self.pad_token), _pad_batch(batch, -100)\n",
    "        return {\"input_ids\": x, \"labels\": y}  # will be shifted in GPT2LMHead forward\n",
    "\n",
    "\n",
    "# Loads tokens and create data loaders for training\n",
    "dataset = MIDIDataset(\n",
    "    tokens_paths, max_seq_len=512, min_seq_len=256, \n",
    ")\n",
    "subset_train, subset_valid = create_subsets(dataset, [0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22574 9674\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
