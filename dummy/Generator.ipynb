{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n42cJmouxDxS",
        "outputId": "9f561c21-03e7-44bb-9d0b-13b91d3b85f7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy\n",
        "import miditok\n",
        "import tqdm\n",
        "from miditok import MIDILike, MIDITokenizer, REMI\n",
        "import pathlib\n",
        "from miditok.constants import CHORD_MAPS\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Config, Trainer, TrainingArguments, GenerationConfig, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2JWQ_xsxafl",
        "outputId": "b694c07f-dc7e-466e-8531-053b3e13aa8b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABXEpdOMxdkN",
        "outputId": "68fd1ece-0889-4bd7-af16-1b9c9a2f674a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the model...\n"
          ]
        }
      ],
      "source": [
        "model_path = \"C:/Users/simas/Downloads/dummy dataset/models/model_dummy/\"\n",
        "\n",
        "pitch_range = range(21, 109)\n",
        "beat_res = {(0, 4): 8, (4, 12): 4}\n",
        "nb_velocities = 32\n",
        "additional_tokens = {'Chord': True, 'Rest': True, 'Tempo': True,\n",
        "                     'rest_range': (2, 8),  # (half, 8 beats)\n",
        "                     'nb_tempos': 32,  # nb of tempo bins\n",
        "                     'tempo_range': (40, 250),  # (min, max)\n",
        "                     'Program': False,\n",
        "                     \"chord_maps\": CHORD_MAPS,\n",
        "                     \"chord_tokens_with_root_note\": True,\n",
        "                     \"chord_unknown\": False}\n",
        "special_tokens = [\"PAD\", \"BOS\", \"EOS\"]\n",
        "\n",
        "tokenizer = MIDILike(pitch_range, beat_res, nb_velocities, additional_tokens, special_tokens=special_tokens)\n",
        "\n",
        "print('Loading the model...')\n",
        "\n",
        "# Creates model\n",
        "config = GPT2Config( \n",
        "    vocab_size=500,\n",
        "    n_positions=10,\n",
        "    n_embd=64,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    n_inner=128,\n",
        "    resid_pdrop=.1,\n",
        "    embd_pdrop=.1,\n",
        "    attn_pdrop=.1,\n",
        "    padding_token_id=tokenizer['PAD_None'],\n",
        "    bos_token_id=tokenizer['BOS_None'],\n",
        "    eos_token_id=tokenizer['EOS_None'],\n",
        ")\n",
        "model = TFGPT2LMHeadModel(config)\n",
        "\n",
        "#model.save_pretrained('/content/gdrive/MyDrive/models/')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiSFuHtzxS1T",
        "outputId": "3bbbfc3e-dfd1-4739-a882-e0d2c07aae46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at C:/Users/simas/Downloads/dummy dataset/models/model_dummy/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel at 0x2372b88d0d0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mYt0t9gOyIAp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# defining our optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "# definining our loss function\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# defining our metric which we want to observe\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "# compiling the model\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsgWikABOFk",
        "outputId": "bf400e46-d369-4d24-ef88-12cf90acdf10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading token files: 100%|██████████| 12/12 [00:00<00:00, 4021.06it/s]\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from miditok.utils import get_midi_programs\n",
        "from miditoolkit import MidiFile\n",
        "\n",
        "\n",
        "midi_path = \"C:/Users/simas/Downloads/dummy dataset/test-gen midi/test.mid\"\n",
        "\n",
        "tokenizer.learn_bpe(\n",
        "    vocab_size=50,\n",
        "    tokens_paths=list(Path('C:/Users/simas/Downloads/dummy dataset/noBPE').glob('**/*.json')),\n",
        "    out_dir=Path('C:/Users/simas/Downloads/dummy dataset/BPE')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "85P_-SIVlxGt"
      },
      "outputs": [],
      "source": [
        "\n",
        "midi = MidiFile(midi_path)\n",
        "token = tokenizer(midi)  # automatically detects MidiFile, paths or tokens before converting them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDjivfILD3wb",
        "outputId": "76f3f2db-1471-4dde-fbd7-93b53b0408e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[65, 53]\n"
          ]
        }
      ],
      "source": [
        "print(token[0].ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HcJAown6mytC"
      },
      "outputs": [],
      "source": [
        "# savetok = Path('/content/gdrive/MyDrive/example midi/token1.json')\n",
        "\n",
        "# tokenizer.save_tokens(token, savetok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GEEpNQuMn1mr"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import os\n",
        "\n",
        "# directory = '/content/gdrive/MyDrive/example midi/tokens/'\n",
        "\n",
        "\n",
        "# for fname in os.listdir(directory):                     # for each file in the directory\n",
        "#     with open(os.path.join(directory, fname)) as i:     # open the file\n",
        "#         data = json.load(i)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq92oHA38voP",
        "outputId": "e7a3e65b-7153-4a12-8ec3-5ccdf66c2fab"
      },
      "outputs": [],
      "source": [
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "q6QqZy8cBBta"
      },
      "outputs": [],
      "source": [
        "prompt = [token[0].ids]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL07Onqdrj71"
      },
      "source": [
        " I have managed to convert a new MIDI to a BPE encoded token, however I am unsure on how to feed the data into the model.generate function to generate a new sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9Tu0912A0Mqu"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=30,  # extends samples by 512 tokens\n",
        "    num_beams=1,        # no beam search\n",
        "    do_sample=True,     # but sample instead\n",
        "    temperature=0.9,\n",
        "    top_k=15,\n",
        "    top_p=0.95,\n",
        "    epsilon_cutoff=3e-4,\n",
        "    eta_cutoff=1e-3,\n",
        "    pad_token_id=config.padding_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6pPuCSZ7o68Q"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "Exception encountered when calling layer 'transformer' (type TFGPT2MainLayer).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,0] = 10 is not in [0, 10) [Op:ResourceGather]\n\nCall arguments received by layer 'transformer' (type TFGPT2MainLayer):\n  • input_ids=tf.Tensor(shape=(1, 1), dtype=int32)\n  • past_key_values=('tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)')\n  • attention_mask=tf.Tensor(shape=(1, 11), dtype=int32)\n  • token_type_ids=None\n  • position_ids=tf.Tensor(shape=(1, 1), dtype=int32)\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34924/1104086030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, seed, **kwargs)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[1;31m# 13. run sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             return self.sample(\n\u001b[0m\u001b[0;32m    968\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, input_ids, logits_processor, logits_warper, max_length, pad_token_id, eos_token_id, seed, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_cond_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinished_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2020\u001b[0m             \u001b[0mmaximum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2021\u001b[1;33m             generated, _, cur_len, _ = tf.while_loop(\n\u001b[0m\u001b[0;32m   2022\u001b[0m                 \u001b[0msample_cond_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2023\u001b[0m                 \u001b[0msample_body_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \"\"\"\n\u001b[1;32m-> 2516\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2764\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2754\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2755\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2756\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2757\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36msample_body_fn\u001b[1;34m(generated, finished_sequences, cur_len, model_kwargs)\u001b[0m\n\u001b[0;32m   1929\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1930\u001b[0m             \u001b[1;31m# forward pass to get next token logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1931\u001b[1;33m             model_outputs = self(\n\u001b[0m\u001b[0;32m   1932\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1933\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \"\"\"\n\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[0;32m    900\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"embedding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         \u001b[0mposition_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'transformer' (type TFGPT2MainLayer).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,0] = 10 is not in [0, 10) [Op:ResourceGather]\n\nCall arguments received by layer 'transformer' (type TFGPT2MainLayer):\n  • input_ids=tf.Tensor(shape=(1, 1), dtype=int32)\n  • past_key_values=('tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)', 'tf.Tensor(shape=(2, 1, 4, 10, 16), dtype=float32)')\n  • attention_mask=tf.Tensor(shape=(1, 11), dtype=int32)\n  • token_type_ids=None\n  • position_ids=tf.Tensor(shape=(1, 1), dtype=int32)\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
          ]
        }
      ],
      "source": [
        "outputs = model.generate(prompt, generation_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx75G9Em0Itt",
        "outputId": "058303ab-34a8-422d-ce37-f0164f670fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "old token: [65, 53]\n",
            "new token: [[65, 53, 225, 702, 702, 9, 49, 227, 578, 599, 415, 599, 962, 811, 508, 227, 599, 227, 685, 98, 701, 98, 86, 86, 420, 426, 426, 685, 779, 643, 599, 884]]\n"
          ]
        }
      ],
      "source": [
        "outputs = tf.Variable(outputs).numpy().tolist()\n",
        "print('old token:', token[0].ids)\n",
        "\n",
        "new_data = token\n",
        "new_data[0].ids = outputs\n",
        "\n",
        "print('new token:', new_data[0].ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmV513R79ZXF"
      },
      "source": [
        "Not sure what the issue is, as the data seems to be in the correct type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F9bi0KN8J8k9"
      },
      "outputs": [],
      "source": [
        "programs = get_midi_programs(midi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34924/1055309775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerated_midi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens_to_midi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprograms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprograms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\miditok\\midi_tokenizer.py\u001b[0m in \u001b[0;36mtokens_to_midi\u001b[1;34m(self, tokens, programs, output_path, time_division)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_tokens\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprograms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m                 track, tempo_changes = self.tokens_to_track(\n\u001b[0m\u001b[0;32m    627\u001b[0m                     \u001b[0mtrack_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_division\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprograms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                 )\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\miditok\\midi_tokenizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                     \u001b[0mevents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0mids_bpe_encoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ids_are_bpe_encoded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 )\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\simas\\anaconda3\\lib\\site-packages\\miditok\\midi_tokenizer.py\u001b[0m in \u001b[0;36m_ids_are_bpe_encoded\u001b[1;34m(self, ids)\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mboolean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mids\u001b[0m \u001b[0mare\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mBPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1415\u001b[0m         \"\"\"\n\u001b[1;32m-> 1416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vocab_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode_bpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTokSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTokSequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size."
          ]
        }
      ],
      "source": [
        "generated_midi1 = tokenizer.tokens_to_midi(new_data[0].ids, programs=programs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Por_Aac5Ks8H"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'generated_midi1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30244/462457419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerated_midi1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/simas/Downloads/dummy dataset/generated midi/generated.mid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'generated_midi1' is not defined"
          ]
        }
      ],
      "source": [
        "generated_midi1.dump('C:/Users/simas/Downloads/dummy dataset/generated midi/generated.mid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aiR-H1vK3-v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
