{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kadAiBTI4p3y"
      },
      "source": [
        "MIDI TOKENIZATION FOR MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki0jfNwMAraa",
        "outputId": "d6c75c2e-4f6a-411a-b9ce-7a6fbbde2550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: miditok in c:\\users\\simas\\anaconda3\\lib\\site-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\simas\\anaconda3\\lib\\site-packages (from miditok) (4.62.3)\n",
            "Requirement already satisfied: miditoolkit>=0.1.16 in c:\\users\\simas\\anaconda3\\lib\\site-packages (from miditok) (0.1.16)\n",
            "Requirement already satisfied: numpy<1.24,>=1.19 in c:\\users\\simas\\anaconda3\\lib\\site-packages (from miditok) (1.20.3)\n",
            "Requirement already satisfied: mido>=1.1.16 in c:\\users\\simas\\anaconda3\\lib\\site-packages (from miditoolkit>=0.1.16->miditok) (1.2.10)\n",
            "Requirement already satisfied: colorama in c:\\users\\simas\\anaconda3\\lib\\site-packages (from tqdm->miditok) (0.4.6)\n",
            "Requirement already satisfied: tokenizers in c:\\users\\simas\\anaconda3\\lib\\site-packages (0.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install miditok\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gRQ69-Wj4p32"
      },
      "outputs": [],
      "source": [
        "from miditok import REMI\n",
        "from miditok.utils import get_midi_programs\n",
        "from miditoolkit import MidiFile\n",
        "from pathlib import Path\n",
        "from miditok.constants import CHORD_MAPS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoDM3F54zXx",
        "outputId": "107e3b5c-daf8-410b-8d70-2329c23bee34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True) #mounts the google drive where the dataset is located"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dox0tAGD4p35"
      },
      "source": [
        "Initiate the tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VUvrRuY15q93"
      },
      "outputs": [],
      "source": [
        "# Our parameters\n",
        "pitch_range = range(21, 109)\n",
        "beat_res = {(0, 4): 8, (4, 12): 4}\n",
        "nb_velocities = 32\n",
        "additional_tokens = {'Chord': True, 'Rest': True, 'Tempo': True,\n",
        "                     'rest_range': (2, 8),  # (half, 8 beats)\n",
        "                     'nb_tempos': 32,  # nb of tempo bins\n",
        "                     'TimeSignature': False,\n",
        "                     'tempo_range': (40, 250),  # (min, max)\n",
        "                     'Program': False,\n",
        "                     \"chord_maps\": CHORD_MAPS,\n",
        "                     \"chord_tokens_with_root_note\": True,\n",
        "                     \"chord_unknown\": False}\n",
        "special_tokens = [\"PAD\", \"BOS\", \"EOS\"]\n",
        "\n",
        "#creates tokenizer\n",
        "tokenizer = REMI(pitch_range, beat_res, nb_velocities, additional_tokens, special_tokens=special_tokens\n",
        "                        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9qk4U7fj4p36"
      },
      "source": [
        "Paths to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVt3_D_G4p36",
        "outputId": "b00e2608-3dd6-4d46-cef9-6eae74aed4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2507\n"
          ]
        }
      ],
      "source": [
        "midi_paths = list(Path(\"/content/gdrive/MyDrive/ala/MIDI/\").glob('**/*.mid'))\n",
        "print(len(midi_paths))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rgmIaHvh4p38"
      },
      "source": [
        "A validation of MIDI files - discarding data that is not usable for machine learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lO59zJ_U4p38"
      },
      "outputs": [],
      "source": [
        "def midi_valid(midi) -> bool:\n",
        "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
        "        return False  # time signature different from 4/*, 4 beats per bar\n",
        "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
        "        return False  # this MIDI is too short\n",
        "    return True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-1U2XRqQ4p39"
      },
      "source": [
        "Converting MIDI to .json tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyTQJIhP4p39",
        "outputId": "dfbff131-8108-4ba2-d6ae-1b144ed172c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Tokenizing MIDIs (Desktop/tokens_noBPE): 100%|██████████| 2507/2507 [00:42<00:00, 59.68it/s] \n",
            "Performing data augmentation: 100%|██████████| 2488/2488 [00:46<00:00, 53.28it/s]\n"
          ]
        }
      ],
      "source": [
        "data_augmentation_offsets = [2, 2, 1]   # will perform data augmentation on 2 pitch octaves,\n",
        "tokenizer.tokenize_midi_dataset(        # 2 velocity and 1 duration values\n",
        "    midi_paths,\n",
        "    Path(\"/content/gdrive/MyDrive/ala/REMI/tokens_noBPE\"),\n",
        "    midi_valid,\n",
        "    data_augmentation_offsets\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F6AsLxMP4p39"
      },
      "source": [
        "Learning the vocabulary with Byte-Paired Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jmvPY52g4p3-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading token files: 100%|██████████| 24385/24385 [00:05<00:00, 4100.43it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.learn_bpe(\n",
        "    vocab_size=1000,\n",
        "    tokens_paths=list(Path(\"/content/gdrive/MyDrive/ala/REMI/tokens_noBPE\").glob('**/*.json')),\n",
        "    out_dir=Path(\"/content/gdrive/MyDrive/ala/REMI/tokens_BPE\"),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YfMT26Zn4p3-"
      },
      "source": [
        "Converting the tokenized musics into tokens with BPE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GsBaLlXU4p3-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Applying BPE to dataset: 100%|██████████| 24385/24385 [01:11<00:00, 341.49it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.apply_bpe_to_dataset(\n",
        "    Path(\"/content/gdrive/MyDrive/ala/REMI/tokens_noBPE\"),\n",
        "    Path(\"/content/gdrive/MyDrive/ala/REMI/tokens_BPE\")\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.save_params(\"/content/gdrive/MyDrive/ala/REMI/params.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
